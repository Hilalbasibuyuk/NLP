{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a17958b-0d60-4e27-8037-91c7a097164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hilal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89a1ec3-6447-4b6c-b6d2-9f561ff02e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.49k/1.49k [00:00<?, ?B/s]\n",
      "c:\\Users\\hilal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hilal\\.cache\\huggingface\\hub\\models--Falconsai--text_summarization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 242M/242M [02:06<00:00, 1.92MB/s] \n",
      "generation_config.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "tokenizer_config.json: 100%|██████████| 2.32k/2.32k [00:00<?, ?B/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 3.40MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.42M/2.42M [00:01<00:00, 2.23MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 1.21MB/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a7804a-2373-4c57-81ed-c6d446ad904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"The company was founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.[1] The company was named after the \"hugging face\" emoji.[1] After open sourcing the model behind the chatbot, the company pivoted to focus on being a platform for machine learning.\n",
    "\n",
    "In March 2021, Hugging Face raised US$40 million in a Series B funding round.[2]\n",
    "\n",
    "On April 28, 2021, the company launched the BigScience Research Workshop in collaboration with several other research groups to release an open large language model.[3] In 2022, the workshop concluded with the announcement of BLOOM, a multilingual large language model with 176 billion parameters.[4][5]\n",
    "\n",
    "In December 2022, the company acquired Gradio, an open source library built for developing machine learning applications in Python.[6]\n",
    "\n",
    "On May 5, 2022, the company announced its Series C funding round led by Coatue and Sequoia.[7] The company received a $2 billion valuation.\n",
    "\n",
    "On August 3, 2022, the company announced the Private Hub, an enterprise version of its public Hugging Face Hub that supports SaaS or on-premises deployment.[8]\n",
    "\n",
    "In February 2023, the company announced partnership with Amazon Web Services (AWS) which would allow Hugging Face's products available to AWS customers to use them as the building blocks for their custom applications. The company also said the next generation of BLOOM will be run on Trainium, a proprietary machine learning chip created by AWS.[9][10][11]\n",
    "\n",
    "In August 2023, the company announced that it raised $235 million in a Series D funding, at a $4.5 billion valuation. The funding was led by Salesforce, and notable participation came from Google, Amazon, Nvidia, AMD, Intel, IBM, and Qualcomm.[12]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43752370-0c4d-48cb-9be3-ea5dbc1e175a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Hugging Face was founded in 2016 by French entrepreneurs Clément Delangue, Julien Chau'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(article, min_length=5, max_length=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
